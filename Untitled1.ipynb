{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "import sys\n",
    "import keras as K\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "tb = pd.read_csv('traingset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "tb = tb.drop(columns=['Unnamed: 0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "tb = tb[['Depth [m]','Torque [%]','Torque [kNm]','Pressure Pump 1 [bar]','status']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Depth [m]  Torque [%]  Torque [kNm]  Pressure Pump 1 [bar]\n",
      "70441        1.71           0             0                      0\n",
      "30956        4.00          47           187                    294\n",
      "154233       0.00           0             0                      2\n",
      "14992        0.10           0             0                      1\n",
      "46237        3.65          99           388                    347\n",
      "...           ...         ...           ...                    ...\n",
      "41993        3.89           0             0                      2\n",
      "97639        0.00           0             0                      1\n",
      "95939        3.57         100           390                    352\n",
      "152315       3.23         100           390                    349\n",
      "117952       0.00           0             0                      2\n",
      "\n",
      "[118180 rows x 4 columns]         Depth [m]  Torque [%]  Torque [kNm]  Pressure Pump 1 [bar]\n",
      "146997  11.890000          23            94                     86\n",
      "73195    3.940000          87           343                    311\n",
      "118631  25.559999          14            57                    127\n",
      "86925   11.720000           0             0                      3\n",
      "166929  10.420000           0             0                      3\n",
      "...           ...         ...           ...                    ...\n",
      "93892    3.620000         100           390                    349\n",
      "30611    8.130000           0             1                      4\n",
      "17247    0.500000           0             0                      1\n",
      "26674    0.000000           0             0                      2\n",
      "10587    0.540000         100           390                    352\n",
      "\n",
      "[50649 rows x 4 columns]         y0  y1  y2  y3  y4\n",
      "70441    0   0   0   1   0\n",
      "30956    1   0   0   0   0\n",
      "154233   0   1   0   0   0\n",
      "14992    0   0   0   1   0\n",
      "46237    1   0   0   0   0\n",
      "...     ..  ..  ..  ..  ..\n",
      "41993    1   0   0   0   0\n",
      "97639    1   0   0   0   0\n",
      "95939    1   0   0   0   0\n",
      "152315   1   0   0   0   0\n",
      "117952   0   1   0   0   0\n",
      "\n",
      "[118180 rows x 5 columns]         y0  y1  y2  y3  y4\n",
      "146997   0   0   0   0   1\n",
      "73195    1   0   0   0   0\n",
      "118631   0   0   0   0   1\n",
      "86925    1   0   0   0   0\n",
      "166929   0   0   1   0   0\n",
      "...     ..  ..  ..  ..  ..\n",
      "93892    1   0   0   0   0\n",
      "30611    0   0   1   0   0\n",
      "17247    0   0   0   1   0\n",
      "26674    0   0   0   1   0\n",
      "10587    0   0   0   1   0\n",
      "\n",
      "[50649 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "# define traning set\n",
    "\n",
    "target_var = 'status'\n",
    "features = list(tb.columns)\n",
    "features.remove(target_var)\n",
    "Class = tb[target_var].unique()\n",
    "Class_dict = dict(zip(Class, range(len(Class))))\n",
    "tb['target'] = tb[target_var].apply(lambda x: Class_dict[x])\n",
    "lb = LabelBinarizer()\n",
    "lb.fit(list(Class_dict.values()))\n",
    "transformed_labels = lb.transform(tb['target'])\n",
    "y_bin_labels = []  # 对多分类进行0-1编码的变量\n",
    "for i in range(transformed_labels.shape[1]):\n",
    "    y_bin_labels.append('y' + str(i))\n",
    "    tb['y' + str(i)] = transformed_labels[:, i]\n",
    "    # 将数据集分为训练集和测试集\n",
    "train_x, test_x, train_y, test_y = train_test_split(tb[features], tb[y_bin_labels], train_size=0.7, test_size=0.3, random_state=0)\n",
    "print(train_x,test_x,train_y, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = K.initializers.glorot_uniform(seed=1)\n",
    "simple_adam = K.optimizers.Adam()\n",
    "model = K.models.Sequential()\n",
    "model.add(K.layers.Dense(units=5, input_dim=4, kernel_initializer=init, activation='relu'))\n",
    "model.add(K.layers.Dense(units=6, kernel_initializer=init, activation='relu'))\n",
    "model.add(K.layers.Dense(units=5, kernel_initializer=init, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer=simple_adam, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training \n",
      "Epoch 1/100\n",
      "118180/118180 [==============================] - 188s 2ms/step - loss: 1.0581 - accuracy: 0.6314\n",
      "Epoch 2/100\n",
      "118180/118180 [==============================] - 147s 1ms/step - loss: 0.9780 - accuracy: 0.6621\n",
      "Epoch 3/100\n",
      "118180/118180 [==============================] - 158s 1ms/step - loss: 0.9732 - accuracy: 0.6650\n",
      "Epoch 4/100\n",
      "118180/118180 [==============================] - 191s 2ms/step - loss: 0.9681 - accuracy: 0.6676\n",
      "Epoch 5/100\n",
      "118180/118180 [==============================] - 188s 2ms/step - loss: 0.9671 - accuracy: 0.6673\n",
      "Epoch 6/100\n",
      "118180/118180 [==============================] - 205s 2ms/step - loss: 0.9668 - accuracy: 0.6685\n",
      "Epoch 7/100\n",
      "118180/118180 [==============================] - 146s 1ms/step - loss: 0.9664 - accuracy: 0.6677\n",
      "Epoch 8/100\n",
      "118180/118180 [==============================] - 171s 1ms/step - loss: 0.9659 - accuracy: 0.6683\n",
      "Epoch 9/100\n",
      "118180/118180 [==============================] - 158s 1ms/step - loss: 0.9657 - accuracy: 0.6680\n",
      "Epoch 10/100\n",
      "118180/118180 [==============================] - 162s 1ms/step - loss: 0.9652 - accuracy: 0.6692\n",
      "Epoch 11/100\n",
      "118180/118180 [==============================] - 214s 2ms/step - loss: 0.9649 - accuracy: 0.66890s\n",
      "Epoch 12/100\n",
      "118180/118180 [==============================] - 199s 2ms/step - loss: 0.9651 - accuracy: 0.6691\n",
      "Epoch 13/100\n",
      "118180/118180 [==============================] - 212s 2ms/step - loss: 0.9650 - accuracy: 0.6694\n",
      "Epoch 14/100\n",
      "118180/118180 [==============================] - 207s 2ms/step - loss: 0.9647 - accuracy: 0.6693\n",
      "Epoch 15/100\n",
      "118180/118180 [==============================] - 199s 2ms/step - loss: 0.9641 - accuracy: 0.6706\n",
      "Epoch 16/100\n",
      "118180/118180 [==============================] - 179s 2ms/step - loss: 0.9639 - accuracy: 0.6706\n",
      "Epoch 17/100\n",
      "118180/118180 [==============================] - 185s 2ms/step - loss: 0.9641 - accuracy: 0.6699\n",
      "Epoch 18/100\n",
      "118180/118180 [==============================] - 209s 2ms/step - loss: 0.9643 - accuracy: 0.67120s - loss: 0.9644 - accuracy: 0.\n",
      "Epoch 19/100\n",
      "118180/118180 [==============================] - 205s 2ms/step - loss: 0.9638 - accuracy: 0.67071s - loss: 0.9636 - accura - ETA: 0s - los\n",
      "Epoch 20/100\n",
      "118180/118180 [==============================] - 202s 2ms/step - loss: 0.9639 - accuracy: 0.6705\n",
      "Epoch 21/100\n",
      "118180/118180 [==============================] - 205s 2ms/step - loss: 0.9634 - accuracy: 0.6713\n",
      "Epoch 22/100\n",
      "118180/118180 [==============================] - 194s 2ms/step - loss: 0.9637 - accuracy: 0.67140s - loss: 0.963\n",
      "Epoch 23/100\n",
      "118180/118180 [==============================] - 195s 2ms/step - loss: 0.9631 - accuracy: 0.67210s\n",
      "Epoch 24/100\n",
      "118180/118180 [==============================] - 185s 2ms/step - loss: 0.9634 - accuracy: 0.6717\n",
      "Epoch 25/100\n",
      "118180/118180 [==============================] - 192s 2ms/step - loss: 0.9632 - accuracy: 0.6712\n",
      "Epoch 26/100\n",
      "118180/118180 [==============================] - 239s 2ms/step - loss: 0.9632 - accuracy: 0.6716\n",
      "Epoch 27/100\n",
      "118180/118180 [==============================] - 207s 2ms/step - loss: 0.9631 - accuracy: 0.6719\n",
      "Epoch 28/100\n",
      "118180/118180 [==============================] - 144s 1ms/step - loss: 0.9632 - accuracy: 0.6719\n",
      "Epoch 29/100\n",
      "118180/118180 [==============================] - 154s 1ms/step - loss: 0.9636 - accuracy: 0.6719\n",
      "Epoch 30/100\n",
      "118180/118180 [==============================] - 147s 1ms/step - loss: 0.9632 - accuracy: 0.6718\n",
      "Epoch 31/100\n",
      "118180/118180 [==============================] - 147s 1ms/step - loss: 0.9625 - accuracy: 0.6719\n",
      "Epoch 32/100\n",
      "118180/118180 [==============================] - 142s 1ms/step - loss: 0.9625 - accuracy: 0.6725\n",
      "Epoch 33/100\n",
      "118180/118180 [==============================] - 134s 1ms/step - loss: 0.9629 - accuracy: 0.67170s - loss: 0.9629 - accuracy\n",
      "Epoch 34/100\n",
      "118180/118180 [==============================] - 132s 1ms/step - loss: 0.9630 - accuracy: 0.6728\n",
      "Epoch 35/100\n",
      "118180/118180 [==============================] - 146s 1ms/step - loss: 0.9623 - accuracy: 0.6725\n",
      "Epoch 36/100\n",
      "118180/118180 [==============================] - 125s 1ms/step - loss: 0.9633 - accuracy: 0.6714\n",
      "Epoch 37/100\n",
      "118180/118180 [==============================] - 126s 1ms/step - loss: 0.9630 - accuracy: 0.6720\n",
      "Epoch 38/100\n",
      "118180/118180 [==============================] - 129s 1ms/step - loss: 0.9630 - accuracy: 0.6719\n",
      "Epoch 39/100\n",
      "118180/118180 [==============================] - 125s 1ms/step - loss: 0.9632 - accuracy: 0.6719\n",
      "Epoch 40/100\n",
      "118180/118180 [==============================] - 125s 1ms/step - loss: 0.9623 - accuracy: 0.6725\n",
      "Epoch 41/100\n",
      "118180/118180 [==============================] - 125s 1ms/step - loss: 0.9628 - accuracy: 0.67170s -\n",
      "Epoch 42/100\n",
      "118180/118180 [==============================] - 2010s 17ms/step - loss: 0.9627 - accuracy: 0.6722\n",
      "Epoch 43/100\n",
      "118180/118180 [==============================] - 159s 1ms/step - loss: 0.9627 - accuracy: 0.6717\n",
      "Epoch 44/100\n",
      "118180/118180 [==============================] - 145s 1ms/step - loss: 0.9629 - accuracy: 0.6720\n",
      "Epoch 45/100\n",
      "118180/118180 [==============================] - 128s 1ms/step - loss: 0.9626 - accuracy: 0.6716\n",
      "Epoch 46/100\n",
      "118180/118180 [==============================] - 128s 1ms/step - loss: 0.9630 - accuracy: 0.6719\n",
      "Epoch 47/100\n",
      "118180/118180 [==============================] - 128s 1ms/step - loss: 0.9631 - accuracy: 0.6722\n",
      "Epoch 48/100\n",
      "118180/118180 [==============================] - 126s 1ms/step - loss: 0.9627 - accuracy: 0.6723\n",
      "Epoch 49/100\n",
      "118180/118180 [==============================] - 180s 2ms/step - loss: 0.9629 - accuracy: 0.6720\n",
      "Epoch 50/100\n",
      "118180/118180 [==============================] - 138s 1ms/step - loss: 0.9625 - accuracy: 0.6713\n",
      "Epoch 51/100\n",
      "118180/118180 [==============================] - 175s 1ms/step - loss: 0.9629 - accuracy: 0.67201s - l - E\n",
      "Epoch 52/100\n",
      "118180/118180 [==============================] - 207s 2ms/step - loss: 0.9625 - accuracy: 0.6722\n",
      "Epoch 53/100\n",
      "118180/118180 [==============================] - 171s 1ms/step - loss: 0.9626 - accuracy: 0.6727\n",
      "Epoch 54/100\n",
      "118180/118180 [==============================] - 164s 1ms/step - loss: 0.9622 - accuracy: 0.6725\n",
      "Epoch 55/100\n",
      "118180/118180 [==============================] - 156s 1ms/step - loss: 0.9628 - accuracy: 0.6727\n",
      "Epoch 56/100\n",
      "118180/118180 [==============================] - 161s 1ms/step - loss: 0.9626 - accuracy: 0.6718\n",
      "Epoch 57/100\n",
      "118180/118180 [==============================] - 157s 1ms/step - loss: 0.9621 - accuracy: 0.6716\n",
      "Epoch 58/100\n",
      "118180/118180 [==============================] - 173s 1ms/step - loss: 0.9625 - accuracy: 0.6719\n",
      "Epoch 59/100\n",
      "118180/118180 [==============================] - 139s 1ms/step - loss: 0.9632 - accuracy: 0.6724\n",
      "Epoch 60/100\n",
      "118180/118180 [==============================] - 132s 1ms/step - loss: 0.9622 - accuracy: 0.6724\n",
      "Epoch 61/100\n",
      "118180/118180 [==============================] - 166s 1ms/step - loss: 0.9629 - accuracy: 0.6712\n",
      "Epoch 62/100\n",
      "118180/118180 [==============================] - 745s 6ms/step - loss: 0.9624 - accuracy: 0.6723\n",
      "Epoch 63/100\n",
      "118180/118180 [==============================] - 1312s 11ms/step - loss: 0.9623 - accuracy: 0.6722\n",
      "Epoch 64/100\n",
      "118180/118180 [==============================] - 529s 4ms/step - loss: 0.9618 - accuracy: 0.67230s - loss:\n",
      "Epoch 65/100\n",
      "118180/118180 [==============================] - 467s 4ms/step - loss: 0.9626 - accuracy: 0.6715\n",
      "Epoch 66/100\n",
      "118180/118180 [==============================] - 485s 4ms/step - loss: 0.9623 - accuracy: 0.6713\n",
      "Epoch 67/100\n",
      "118180/118180 [==============================] - 451s 4ms/step - loss: 0.9626 - accuracy: 0.6719\n",
      "Epoch 68/100\n",
      "  9378/118180 [=>............................] - ETA: 5:18 - loss: 0.9478 - accuracy: 0.6771 ETA: 4:48 - loss: 0.9478 - accu - ETA: 4:59 - loss: 0.9475 WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (0.118629). Check your callbacks.\n",
      "  9379/118180 [=>............................] - ETA: 5:33 - loss: 0.9479 - accuracy: 0.6770WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (0.114158). Check your callbacks.\n",
      "  9380/118180 [=>............................] - ETA: 5:36 - loss: 0.9479 - accuracy: 0.6771WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (0.114158). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  9381/118180 [=>............................] - ETA: 5:40 - loss: 0.9478 - accuracy: 0.6771WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (0.134607). Check your callbacks.\n",
      "  9382/118180 [=>............................] - ETA: 5:43 - loss: 0.9477 - accuracy: 0.6771WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (0.134607). Check your callbacks.\n",
      "WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (0.134607). Check your callbacks.\n",
      "  9384/118180 [=>............................] - ETA: 5:44 - loss: 0.9478 - accuracy: 0.6771WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (0.152107). Check your callbacks.\n",
      "  9385/118180 [=>............................] - ETA: 5:51 - loss: 0.9477 - accuracy: 0.6771WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (0.134607). Check your callbacks.\n",
      "WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (0.134607). Check your callbacks.\n",
      "  9401/118180 [=>............................] - ETA: 6:17 - loss: 0.9478 - accuracy: 0.6772 ETA: 6:05 - loss: 0.9480 - accuracyWARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (0.112008). Check your callbacks.\n",
      "  9402/118180 [=>............................] - ETA: 6:21 - loss: 0.9478 - accuracy: 0.6772WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (0.133222). Check your callbacks.\n",
      "  9403/118180 [=>............................] - ETA: 6:25 - loss: 0.9477 - accuracy: 0.6772WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (0.184012). Check your callbacks.\n",
      "  9404/118180 [=>............................] - ETA: 6:29 - loss: 0.9476 - accuracy: 0.6773WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (0.184012). Check your callbacks.\n",
      "  9405/118180 [=>............................] - ETA: 6:31 - loss: 0.9476 - accuracy: 0.6773WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (0.233199). Check your callbacks.\n",
      "  9406/118180 [=>............................] - ETA: 6:35 - loss: 0.9475 - accuracy: 0.6773WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (0.224411). Check your callbacks.\n",
      "  9407/118180 [=>............................] - ETA: 6:38 - loss: 0.9475 - accuracy: 0.6774WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (0.177246). Check your callbacks.\n",
      "WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (0.127635). Check your callbacks.\n",
      "  9409/118180 [=>............................] - ETA: 6:39 - loss: 0.9475 - accuracy: 0.6773WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (0.127880). Check your callbacks.\n",
      "  9410/118180 [=>............................] - ETA: 6:40 - loss: 0.9475 - accuracy: 0.6774WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (0.127880). Check your callbacks.\n",
      "  9548/118180 [=>............................] - ETA: 8:42 - loss: 0.9494 - accuracy: 0.6761 ETA: 7: - ETA: 7:42 - loss: 0 - ETA: 8:22 - loss: 0.9494 - WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (0.122303). Check your callbacks.\n",
      "  9549/118180 [=>............................] - ETA: 8:45 - loss: 0.9495 - accuracy: 0.6760WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (0.147264). Check your callbacks.\n",
      "  9550/118180 [=>............................] - ETA: 8:48 - loss: 0.9494 - accuracy: 0.6760WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (0.122303). Check your callbacks.\n",
      "  9555/118180 [=>............................] - ETA: 8:56 - loss: 0.9493 - accuracy: 0.6760WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (0.121052). Check your callbacks.\n",
      "  9621/118180 [=>............................] - ETA: 10:07 - loss: 0.9503 - accuracy: 0.6761WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (0.103618). Check your callbacks.\n",
      "  9933/118180 [=>............................] - ETA: 14:31 - loss: 0.9527 - accuracy: 0.6760- ETA: 10:46 - loss: 0.9507 - accuracy: 0.676 - ETA: 10:48 - loss: 0.9506 - accuracy: 0.6 - ETA: 10:52 - loss: 0.9508 - accuracy: 0.6 - ETA: 10:5 - ETA: 12:48 - loss: 0.9526 - accuracy: 0.67 - ETA: 12:49 - loss: 0.9524 -  - ETA: 13:17 - loss: 0.9524 - accurac - WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (0.114113). Check your callbacks.\n",
      "  9934/118180 [=>............................] - ETA: 14:34 - loss: 0.9527 - accuracy: 0.6760WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (0.121780). Check your callbacks.\n",
      "  9961/118180 [=>............................] - ETA: 15:07 - loss: 0.9534 - accuracy: 0.6756- ETA: 14:40 - loss: 0.9526 -WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (0.117110). Check your callbacks.\n",
      "  9962/118180 [=>............................] - ETA: 15:11 - loss: 0.9534 - accuracy: 0.6757WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (0.117110). Check your callbacks.\n",
      "  9964/118180 [=>............................] - ETA: 15:12 - loss: 0.9535 - accuracy: 0.6756WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (0.117110). Check your callbacks.\n",
      "  9965/118180 [=>............................] - ETA: 15:14 - loss: 0.9536 - accuracy: 0.6756WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (0.108837). Check your callbacks.\n",
      "  9966/118180 [=>............................] - ETA: 15:14 - loss: 0.9535 - accuracy: 0.6756WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (0.108837). Check your callbacks.\n",
      "  9967/118180 [=>............................] - ETA: 15:17 - loss: 0.9535 - accuracy: 0.6756WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (0.108837). Check your callbacks.\n",
      "  9968/118180 [=>............................] - ETA: 15:17 - loss: 0.9537 - accuracy: 0.6756WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (0.111348). Check your callbacks.\n",
      "  9990/118180 [=>............................] - ETA: 15:59 - loss: 0.9536 - accuracy: 0.6756WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (0.109290). Check your callbacks.\n",
      "  9991/118180 [=>............................] - ETA: 16:03 - loss: 0.9535 - accuracy: 0.6756WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (0.109290). Check your callbacks.\n",
      " 10318/118180 [=>............................] - ETA: 20:24 - loss: 0.9536 - accuracy: 0.6753- ETA: 16:27 - loss: 0.9537 - accuracy:  - ETA: 16:34 - loss: 0.9540 - accuracy: 0.67 - ETA: 16:35 - loss: 0.9541 - ETA: 17:03 - loss: 0.9534 - accuracy:  - ETA: 17:08 - loss: 0.9533 - accu - ETA: 17:23 - lo - ETA: 19:36 - loss: 0.9534 - accuracy: 0.67 - ETA: 19:38 - loss: 0.9535 - accu - ETA: 19:56 - loss: 0.953 - ETA: 20:11 - loss: 0.9532 - accuracy: 0 - ETA: 20:17 - loss: 0.9531 - accuracy: 0.6 - ETA: 20:19 - loss: 0.9533 - accuracy: 0.67WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (0.101375). Check your callbacks.\n",
      " 10319/118180 [=>............................] - ETA: 20:27 - loss: 0.9535 - accuracy: 0.6754WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (0.101375). Check your callbacks.\n",
      " 10320/118180 [=>............................] - ETA: 20:28 - loss: 0.9538 - accuracy: 0.6753WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (0.101375). Check your callbacks.\n",
      " 10324/118180 [=>............................] - ETA: 20:33 - loss: 0.9538 - accuracy: 0.6753- ETA: 20:30 - loss: 0.9539 - accuracy: 0.67WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (0.137419). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 10325/118180 [=>............................] - ETA: 20:35 - loss: 0.9538 - accuracy: 0.6754WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (0.162239). Check your callbacks.\n",
      " 10326/118180 [=>............................] - ETA: 20:38 - loss: 0.9537 - accuracy: 0.6754WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (0.137419). Check your callbacks.\n",
      " 10330/118180 [=>............................] - ETA: 20:42 - loss: 0.9536 - accuracy: 0.6754WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (0.101419). Check your callbacks.\n",
      " 10331/118180 [=>............................] - ETA: 20:44 - loss: 0.9537 - accuracy: 0.6753WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (0.101419). Check your callbacks.\n",
      " 10337/118180 [=>............................] - ETA: 20:57 - loss: 0.9534 - accuracy: 0.6754WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (0.118048). Check your callbacks.\n",
      " 10338/118180 [=>............................] - ETA: 20:58 - loss: 0.9534 - accuracy: 0.6755WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (0.118048). Check your callbacks.\n",
      " 10339/118180 [=>............................] - ETA: 20:59 - loss: 0.9534 - accuracy: 0.6755WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (0.118048). Check your callbacks.\n",
      " 10340/118180 [=>............................] - ETA: 21:05 - loss: 0.9533 - accuracy: 0.6755WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (0.118048). Check your callbacks.\n",
      " 10341/118180 [=>............................] - ETA: 21:08 - loss: 0.9533 - accuracy: 0.6755WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (0.118048). Check your callbacks.\n",
      "WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (0.118048). Check your callbacks.\n",
      " 10613/118180 [=>............................] - ETA: 24:10 - loss: 0.9533 - accuracy: 0.6759- ETA: 21:35 - loss: 0.9528 - accuracy: 0.67 - ETA: 21:38 - loss: 0.9527 - accuracy: 0.676 - ETA: 21:39 - loss: 0.9527   - ETA: 22:50 - loss: 0.9535 - accuracy: 0. - ETA: 22:57 - loss: 0.9533 - a - ETA: 23:13 - loss: 0.9534 - ac - ETA: 23:41 - loss: 0.9531 - accuracy: - ETA: 23:50 - loss: 0.9532 - acc - ETA: 24:05 - loss: 0.9532 - accuracy: 0.675WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (0.131322). Check your callbacks.\n",
      " 10614/118180 [=>............................] - ETA: 24:11 - loss: 0.9533 - accuracy: 0.6759WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (0.152271). Check your callbacks.\n",
      " 10615/118180 [=>............................] - ETA: 24:14 - loss: 0.9534 - accuracy: 0.6758WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (0.157208). Check your callbacks.\n",
      " 10616/118180 [=>............................] - ETA: 24:16 - loss: 0.9534 - accuracy: 0.6759WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (0.157208). Check your callbacks.\n",
      " 10617/118180 [=>............................] - ETA: 24:20 - loss: 0.9533 - accuracy: 0.6759WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (0.157208). Check your callbacks.\n",
      " 10618/118180 [=>............................] - ETA: 24:23 - loss: 0.9533 - accuracy: 0.6759WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (0.157208). Check your callbacks.\n",
      " 10619/118180 [=>............................] - ETA: 24:23 - loss: 0.9532 - accuracy: 0.6760WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (0.157208). Check your callbacks.\n",
      " 10620/118180 [=>............................] - ETA: 24:25 - loss: 0.9531 - accuracy: 0.6760WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (0.110055). Check your callbacks.\n",
      " 10621/118180 [=>............................] - ETA: 24:28 - loss: 0.9531 - accuracy: 0.6760WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (0.110055). Check your callbacks.\n",
      " 10630/118180 [=>............................] - ETA: 24:42 - loss: 0.9529 - accuracy: 0.6762WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (0.121247). Check your callbacks.\n",
      " 10632/118180 [=>............................] - ETA: 24:46 - loss: 0.9528 - accuracy: 0.6763WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (0.107640). Check your callbacks.\n",
      " 10638/118180 [=>............................] - ETA: 24:56 - loss: 0.9530 - accuracy: 0.6762WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (0.120150). Check your callbacks.\n",
      " 10639/118180 [=>............................] - ETA: 24:59 - loss: 0.9529 - accuracy: 0.6762WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (0.101162). Check your callbacks.\n",
      " 10828/118180 [=>............................] - ETA: 27:16 - loss: 0.9540 - accuracy: 0.6757- ETA: 25:19 - loss: 0.9529 - ETA: 26:24 - loss: 0.9535 - accu - ETA: 26:30 - loss: 0.9533 - accuracy: - ETA: 26:35 - loss: 0.9534 - accuracy: 0. - ETA: 26:37 - loss: - ETA: 27:11 - loss: 0.9540 - accuracy: 0.67WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (0.111536). Check your callbacks.\n",
      " 10829/118180 [=>............................] - ETA: 27:20 - loss: 0.9541 - accuracy: 0.6757WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (0.122052). Check your callbacks.\n",
      " 12743/118180 [==>...........................] - ETA: 39:48 - loss: 0.9569 - accuracy: 0.6744- ETA: 27:23 - loss: - ETA: 27:57 - loss: 0.9535 - acc - ETA: 28:07 - loss: 0.9536  - ETA: 28:24 - loss: 0.9537 - accuracy - ETA: 28:25 - loss: 0.9536  - ETA: 28:41 - loss: 0.9541 - accuracy: 0.67 - ETA: 28:43 - loss: 0.9539 - accur - ETA: 28:52 - loss: 0.9538 - accuracy:  - ETA: 28:56 - loss: 0.9536 - accuracy: 0. - ETA: 28:59 - - ETA: 29:19 - loss: 0.9 - ETA: 29:37 - loss: 0.9540 - ac - ETA: 29:44 - loss: 0.9541 - accuracy:  - ETA: 29:46 - loss: 0.954 - ETA: 30:01 - loss: 0.9 - ETA: 30:33 - - ETA: 31:04 - loss: 0.9558 - accuracy: - ETA: 31:16 - loss: 0.9558 - accuracy: 0.67 - ETA: 31:18 - loss: 0.9560 - accuracy: 0.67 - ETA: 31:20 - loss: 0.9559 - accuracy: 0.6 - ETA: 31:26 - loss: 0.9558 - accu - ETA: 31:44 - loss: 0.9561 - acc - ETA: 32:04 - loss: 0.955 - ETA: 32:13 - loss: 0.9551 - accuracy: 0.67 - ETA: 32:15 - loss: 0.9550 - accuracy: 0.67 - ETA: 32:18 - loss: 0.95 - ETA: 32:33 - loss: 0.9552 - accuracy:  - ETA: 32:37 - loss: 0.9554 - accuracy: 0 - ETA: 32: - - ETA: 34:11 - loss: 0.9553 - accuracy: - ETA: 34:16 - loss: 0.9551 - accuracy:  - ETA: 34:20 - loss: 0.9553 - accuracy: 0 - ETA: 34:23  - ETA: 34:40 - loss: 0.9551 - accuracy: - ETA: 34:47 - loss: 0.9 - ETA: 35:00 - loss: 0.9555 - accur - ETA: 35 - ETA: 35:5 - ETA: 36:11 - loss: 0.9546 - accu - ETA: 36:17 - loss: 0.9544 - accuracy: 0.676 - ETA: - ETA: 36:46 - loss: 0.954 - ETA: 36:53 - loss: 0.9542 - accuracy - ETA: 36:57 - loss: 0.9544 - accurac - ETA: 37:02 - loss: 0.9548 - accuracy: 0. - ETA: 37:05 - loss: 0.9546 - accuracy:  - ETA: 37:08 - loss: 0.954 - ETA: 37:17 - loss: 0.955 - ETA: 37:28 - loss: 0.9546 - ETA: 37:39 - loss:  - ETA: 37:53 - loss: 0.9544 - accurac - ETA: 37:57 - los - ETA: 38:07 - loss: 0.9547 - acc - ETA: 38:14 - loss: 0.9557 - ac - ETA: 38:41 - ETA: 38:58 - loss: 0.9552 - accuracy: 0.6 - ETA: 38:59 - loss:  - ETA: 39:15 - loss: 0.9560 - accuracy - ETA: 39:21 - loss: 0.9559 - accuracy: 0. - ETA: 39:23 - loss: 0.9561 - accu - ETA: 39:24 - loss: 0.9567 - accurac - ETA: 39:30 - l - ETA: 39:48 - loss: 0.9570 - accuracy: 0.674WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (0.100592). Check your callbacks.\n",
      " 12744/118180 [==>...........................] - ETA: 39:49 - loss: 0.9569 - accuracy: 0.6744WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (0.100592). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 12745/118180 [==>...........................] - ETA: 39:50 - loss: 0.9570 - accuracy: 0.6744WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (0.105881). Check your callbacks.\n",
      "118180/118180 [==============================] - 779s 7ms/step - loss: 0.9629 - accuracy: 0.6713\n",
      "Epoch 69/100\n",
      "118180/118180 [==============================] - 180s 2ms/step - loss: 0.9623 - accuracy: 0.6721\n",
      "Epoch 70/100\n",
      "118180/118180 [==============================] - 178s 2ms/step - loss: 0.9620 - accuracy: 0.6724\n",
      "Epoch 71/100\n",
      "118180/118180 [==============================] - 131s 1ms/step - loss: 0.9623 - accuracy: 0.6721\n",
      "Epoch 72/100\n",
      "118180/118180 [==============================] - 157s 1ms/step - loss: 0.9627 - accuracy: 0.6717\n",
      "Epoch 73/100\n",
      "118180/118180 [==============================] - 172s 1ms/step - loss: 0.9629 - accuracy: 0.6719\n",
      "Epoch 74/100\n",
      "118180/118180 [==============================] - 135s 1ms/step - loss: 0.9627 - accuracy: 0.6724\n",
      "Epoch 75/100\n",
      "118180/118180 [==============================] - 135s 1ms/step - loss: 0.9625 - accuracy: 0.6718\n",
      "Epoch 76/100\n",
      "118180/118180 [==============================] - 128s 1ms/step - loss: 0.9625 - accuracy: 0.6717\n",
      "Epoch 77/100\n",
      "118180/118180 [==============================] - 129s 1ms/step - loss: 0.9625 - accuracy: 0.6720\n",
      "Epoch 78/100\n",
      "118180/118180 [==============================] - 156s 1ms/step - loss: 0.9619 - accuracy: 0.6727\n",
      "Epoch 79/100\n",
      "118180/118180 [==============================] - 140s 1ms/step - loss: 0.9626 - accuracy: 0.6724\n",
      "Epoch 80/100\n",
      "118180/118180 [==============================] - 139s 1ms/step - loss: 0.9620 - accuracy: 0.6718\n",
      "Epoch 81/100\n",
      "118180/118180 [==============================] - 138s 1ms/step - loss: 0.9625 - accuracy: 0.6721\n",
      "Epoch 82/100\n",
      "118180/118180 [==============================] - 187s 2ms/step - loss: 0.9627 - accuracy: 0.6715\n",
      "Epoch 83/100\n",
      "118180/118180 [==============================] - 147s 1ms/step - loss: 0.9623 - accuracy: 0.6718\n",
      "Epoch 84/100\n",
      "118180/118180 [==============================] - 154s 1ms/step - loss: 0.9624 - accuracy: 0.6721\n",
      "Epoch 85/100\n",
      "118180/118180 [==============================] - 160s 1ms/step - loss: 0.9621 - accuracy: 0.6720\n",
      "Epoch 86/100\n",
      "118180/118180 [==============================] - 179s 2ms/step - loss: 0.9622 - accuracy: 0.6719\n",
      "Epoch 87/100\n",
      "118180/118180 [==============================] - 217s 2ms/step - loss: 0.9626 - accuracy: 0.6708\n",
      "Epoch 88/100\n",
      "118180/118180 [==============================] - 172s 1ms/step - loss: 0.9625 - accuracy: 0.6722\n",
      "Epoch 89/100\n",
      "118180/118180 [==============================] - 141s 1ms/step - loss: 0.9623 - accuracy: 0.6719\n",
      "Epoch 90/100\n",
      "118180/118180 [==============================] - 162s 1ms/step - loss: 0.9625 - accuracy: 0.67180s - loss: 0.9625 - \n",
      "Epoch 91/100\n",
      "118180/118180 [==============================] - 159s 1ms/step - loss: 0.9621 - accuracy: 0.6719\n",
      "Epoch 92/100\n",
      "118180/118180 [==============================] - 156s 1ms/step - loss: 0.9616 - accuracy: 0.6725\n",
      "Epoch 93/100\n",
      "118180/118180 [==============================] - 171s 1ms/step - loss: 0.9620 - accuracy: 0.6721\n",
      "Epoch 94/100\n",
      "118180/118180 [==============================] - 139s 1ms/step - loss: 0.9624 - accuracy: 0.6724\n",
      "Epoch 95/100\n",
      "118180/118180 [==============================] - 184s 2ms/step - loss: 0.9625 - accuracy: 0.6717\n",
      "Epoch 96/100\n",
      "118180/118180 [==============================] - 173s 1ms/step - loss: 0.9625 - accuracy: 0.6710\n",
      "Epoch 97/100\n",
      "118180/118180 [==============================] - 165s 1ms/step - loss: 0.9623 - accuracy: 0.67250s - loss: 0.9623 - \n",
      "Epoch 98/100\n",
      "118180/118180 [==============================] - 156s 1ms/step - loss: 0.9623 - accuracy: 0.6720\n",
      "Epoch 99/100\n",
      "118180/118180 [==============================] - 126s 1ms/step - loss: 0.9627 - accuracy: 0.6722\n",
      "Epoch 100/100\n",
      "118180/118180 [==============================] - 150s 1ms/step - loss: 0.9623 - accuracy: 0.6725\n",
      "Training finished \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 3. training\n",
    "b_size = 1\n",
    "max_epochs = 100\n",
    "print(\"Starting training \")\n",
    "h = model.fit(train_x, train_y, batch_size=b_size, epochs=max_epochs, shuffle=True, verbose=1)\n",
    "print(\"Training finished \\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation on test data: loss = 0.956897 accuracy = 66.87% \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 4. \n",
    "eval = model.evaluate(test_x, test_y, verbose=0)\n",
    "print(\"Evaluation on test data: loss = %0.6f accuracy = %0.2f%% \\n\" \\\n",
    "          % (eval[0], eval[1] * 100) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
